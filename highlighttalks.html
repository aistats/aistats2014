<p><b>Bayesian Monitoring for the Comprehensive Nuclear-Test-Ban Treaty</b><br>
Stuart Russell*, <i>UC Berkeley</i>; Erik Sudderth; Nimar Arora, <i>Bayesian Logic Inc.</i>

<p>Verification for the Comprehensive Nuclear-Test-Ban Treaty requires detecting
and characterizing all seismic events above a minimum magnitude occurring
anywhere on Earth. The treaty defines a network of sensors, the International
Monitoring System (IMS), managed by the United Nations CTBTO. NET-VISA,
a Bayesian monitoring system applied to IMS data, exhibits a 2x-3x reduction
in detection failures compared to the current CTBTO system; the UN has
recommended its deployment for treaty verification, subject to approval by
member states.     
<p>NET-VISAâ€™s prior is a complex, open-universe generative probability
model (written originally in the Bayesian Logic formal language and trained
on historical data) describing event occurrence, signal propagation, signal
detection, and noise processes; the evidence consists of "blips" (above-threshold
signals, 90% of which are noise) extracted from raw IMS waveform data. More
recent work extends the generative model all the way to the raw waveforms,
promising greater sensitivity but requiring new modeling and inference techniques.  

<p>Reference: Nimar S. Arora, Stuart Russell, and Erik Sudderth, ``NET-VISA:
Network Processing Vertically Integrated Seismic Analysis.'' In <i>Bulletin
of the Seismological Society of America</i>, 103(2A), 709-729, 2013.
<a href="http://www.bssaonline.org/content/103/2A/709.abstract">http://www.bssaonline.org/content/103/2A/709.abstract</a>
<br><br>


<p><b>Analysis of Forensic DNA Mixtures with Artefacts using Bayesian networks</b><br>
Julia Mortera*, <i>Universita' Roma Tre</i>; Steffen  Lauritzen, <i>University of Oxford</i>; Therese Graversen; Robert Cowell, <i>City University</i>

<p>DNA is now routinely used in criminal investigations and court cases,
although DNA samples taken at crime scenes are of varying quality and
therefore present challenging problems for their interpretation.    
We present a statistical model for the quantitative peak information
obtained from an electropherogram (EPG) of a forensic DNA sample and
illustrate its potential use for the analysis of criminal cases. In
contrast to most previously used methods, we directly model the peak
height information and incorporates important artefacts associated
with the production of the EPG. Our model has a number of unknown
parameters, and we show that these can be estimated by the method of
maximum likelihood in the presence of multiple unknown contributors,
and their approximate standard errors calculated; the computations
exploit a Bayesian network representation of the model.  A case example
from a UK trial, as reported in the literature, is used to illustrate
the efficacy and use of the model, both in finding likelihood ratios
to quantify the strength of evidence, and in the deconvolution of
mixtures for the purpose of finding likely profiles of one or more
unknown contributors to a DNA sample.     
Our model is readily extended to simultaneous analysis of more than
one mixture as illustrated in a case example. We show that combination
of evidence from several samples may give an evidential strength close
to that of a single source trace and thus modelling of peak height
information provides for a potentially very efficient mixture
analysis.
Joint work with Therese Graversen, Steffen Lauritzen and Robert Cowell.
<br><br>


<p><b>Gaussian Processes for Data-Efficient Learning in Robotics and
Control</b><br>
Marc Deisenroth*; Dieter Fox, <i>University of Washington</i>; Carl
Rasmussen

<p>Autonomous reinforcement learning (RL) approaches typically require
many interactions with the system to learn controllers, which is a
practical limitation in real systems, such as robots, where many
interactions can be impractical and time consuming. To address this
problem, current learning approaches typically require task-specific
knowledge in form of expert demonstrations, realistic simulators,
pre-shaped policies, or specific knowledge about the underlying
dynamics. We follow a different approach and speed up learning by
extracting more information from data. In particular, we learn a
probabilistic, non-parametric Gaussian process transition model of
the system. By explicitly incorporating model uncertainty into
long-term planning and controller learning our approach reduces
the effects of model errors, a key problem in model-based learning.
Compared to state-of-the art RL our model-based policy search
method achieves an unprecedented speed of learning. We demonstrate
its applicability to autonomous learning in challenging real
robot and control tasks.

<p>Reference: MP Deisenroth, D Fox, and CE Rasmussen. Gaussian
Processes for Data-Efficient Learning in Robotics and Control.
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>,
2014. Accepted for publication.
<a href="http://doi.ieeecomputersociety.org/10.1109/TPAMI.2013.218">http://doi.ieeecomputersociety.org/10.1109/TPAMI.2013.218</a>
<br><br>


<p><b>Spatiotemporal point process models of conflicts</b><br>
Andrew Zammit-Mangion, <i>University of Bristol</i>; Michael Dewar,
<i>New York Times</i>; Visakan Kadirkamanathan, <i>University of
Sheffield</i>; Guido Sanguinetti*

<p>Modern conflicts are characterised by an ever increasing use of
information and sensing technology, resulting in vast amounts of high
resolution data. Modelling and prediction of conflict, however,
remains a challenging task due to the heterogeneous and dynamic nature
of the data typically available. Here we propose the use of dynamic
spatiotemporal modelling tools for the identification of complex
underlying processes in conflict, such as diffusion, relocation,
heterogeneous escalation and volatility. Using ideas from statistics,
signal processing and ecology, we provide a predictive framework able
to assimilate data and give confidence estimates on the
predictions. We demonstrate our methods on the Wikileaks Afghan War
Diary. Our results show that the approach allows deeper insights into
conflict dynamics and allows a strikingly accurate (in a statistical
sense) forward prediction of armed opposition group activity in 2010,
based solely on data from previous years.

<p>Reference: Andrew Zammit-Mangion, Michael Dewar, Visakan
Kadirkamanathan, and Guido Sanguinetti, Point process modelling of the
Afghan War Diary,
<i>Proc Natl Acad Sci U S A.</i> 2012 July 31; 109(31): 12414-12419
Web:
<a href="http://www.pnas.org/content/early/2012/07/11/1203177109.abstract"http://www.pnas.org/content/early/2012/07/11/1203177109.abstract</a>
<br><br>


<p><b>Representation Learning: A Review and New Perspectives</b><br>
Yoshua Bengio*

<p>The success of machine learning algorithms generally depends on
data representation, and we hypothesize that this is because different
representations can entangle and hide more or less the different
explanatory factors of variation behind the data.  Although specific
domain knowledge can be used to help design representations, learning
with generic priors can also be used, and the quest for AI is
motivating the design of more powerful representation-learning
algorithms implementing such priors. This paper reviews recent work in
the area of unsupervised feature learning and deep learning, covering
advances in probabilistic models, auto-encoders, manifold learning,
and deep networks.  This motivates longer-term unanswered questions
about the appropriate objectives for learning good representations,
for computing representations (i.e., inference), and the geometrical
connections between representation learning, density estimation and
manifold learning.

<p>Yoshua Bengio, Aaron Courville, Pascal Vincent, "Representation
Learning: A Review and New Perspectives," <i>IEEE Transactions on
Pattern Analysis and Machine Intelligence</i>, vol. 35, no. 8, pp. 1798-1828, Aug. 2013, doi:10.1109/TPAMI.2013.50
<a href="http://www.computer.org/csdl/trans/tp/2013/08/ttp2013081798-abs.html">http://www.computer.org/csdl/trans/tp/2013/08/ttp2013081798-abs.html</a>
<br><br>


