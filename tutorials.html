---
layout: default
---

<script type="text/javascript">
    document.getElementById('LNtutorial').id='leftcurrent';
</script>


<div class="contents">

<h1>AISTATS*2014 Tutorials</h1>

<p>April 25 is a joint tutorial day of AISTATS and the 
<a href="http://mlss2014.hiit.fi/">MLSS Machine Learning Summer School</a>.


<p><h2>Tutorial Speakers</h2>

<table border="0">

<tr>
<td valign="top"><img border="0" width="120" src="{{ site.baseurl }}/img/roderick_murray_smith.jpg"></td>
<td valign="top">
<a href="http://www.dcs.gla.ac.uk/~rod/">Roderick Murray-Smith</a>, 
<i>University of Glasgow</i>

<p><b>Machine learning and Human Computer Interaction</b>

<p>The opportunities for interaction with computer systems are rapidly expanding beyond traditional input and 
output paradigms: full-body motion sensors, brain-computer interfaces, 3D displays, touch panels are now 
commonplace commercial items. The profusion of new sensing devices for human input and the new display channels 
which are becoming available offer the potential to create more involving, expressive and efficient interactions 
in a much wider range of contexts. Dealing with these complex sources of human intention requires appropriate 
mathematical methods; modelling and analysis of interactions requires sophisticated methods which can transform 
streams of data from complex sensors into estimates of human intention.

<p>This tutorial will focus on the use of inference and dynamical modelling in human-computer interaction. The 
combination of modern statistical inference and real-time closed loop modelling offers rich possibilities in 
building interactive systems, but there is a significant gap between the techniques commonly used in HCI and the 
mathematical tools available in other fields of computing science. This tutorial aims to illustrate how to bring 
these mathematical tools to bear on interaction problems, and will cover basic theory and example applications 
from mobile interaction, interaction with large music collections and full-body interaction.

</td>
</tr>


<tr>
<td valign="top"><img border=20" width="120" src="{{ site.baseurl }}/img/christian_p_robert.jpg"></td>
<td valign="top">
<a href="https://www.ceremade.dauphine.fr/~xian/">Christian P. Robert</a>, 
<i>Ceremade - Universit&eacute; Paris-Dauphine</i>

<p><b>Approximate Bayesian computation (ABC), methodology and applications</b>

<p>ABC appeared in 1999 to solve complex genetic problems where the likelihood of the model was impossible 
to compute. They are now a standard tool in the statistical genetic community but have also addressed many 
other problems where likelihood computation was also an issue, including dynamic models in signal 
processing and financial data analysis. However, these methods suffer to some degree from calibration 
difficulties that make them rather volatile in their implementation and thus render them suspicious to the 
users of more traditional Monte Carlo methods. Nonetheless, ABC techniques have several claims to 
validity: first, they are connected with econometric methods like indirect inference. Second, they can be 
expressed in terms of various non-parametric estimators of the likelihood or of the posterior density and 
follow standard convergence patterns. At last, they appear as regular Bayesian inference over noisy data.  
The tutorial covers those validation steps but also details different implementations of ABC algorithms 
and calibration of their parameters.


</td>
</tr>



<tr>
<td valign="top"><img border="0" width="120" src="{{ site.baseurl }}/img/havard_rue.jpg"></td>
<td valign="top">
<a href="http://www.ntnu.edu/employees/havard.rue">H&aring;vard Rue</a>,
<i>Norwegian University of Science and Technology</i>

<p><b>Bayesian computing with INLA</b>

<p>In this lecture, I will discuss approximate Bayesian inference for the
class of latent Gaussian models (LGMs). LGMs are perhaps the most
commonly used class of models in statistical applications. It includes,
among others, most of (generalised) linear models, (generalised)
additive models, smoothing spline models, state space models,
semiparametric regression, spatial and spatiotemporal models,
log-Gaussian Cox processes and geostatistical and geoadditive models.

<p>The concept of LGMs is extremely useful when doing inference as we can
treat models listed above in a unified way and using the same algorithms
and software tool. Our approach to (approximate) Bayesian inference, is
to use integrated nested Laplace approximations (INLA). Using this new
tool, we can directly compute very accurate approximations to the
posterior marginals. Another advantage with our approach is its
generality, which makes it possible to perform Bayesian analysis in an
automatic, streamlined way, and to compute model comparison criteria and
various predictive measures so that models can be compared and the model
under study can be challenged.

<p>I will discuss the background for understanding LGM and INLA, end by
illustrating INLA on some examples in R. Please visit 
<a href="http://www.r-inla.org">www.r-inla.org</a> to
download the package and for further information.
</td>
</tr>


</table>







</div>

<!--- XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX -->
<!--<.html include("./includes/aistatstail.html"); ?>-->
